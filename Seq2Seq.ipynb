{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\djaym7\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import helpers\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "EOS = 1\n",
    "\n",
    "vocab_size = 10\n",
    "input_embedding_size = 20\n",
    "\n",
    "encoder_hidden_units = 20\n",
    "decoder_hidden_units =  encoder_hidden_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#placeholders\n",
    "encoder_inputs = tf.placeholder(shape=(None,None),dtype=tf.int32,name='encoder_inputs')\n",
    "decoder_targets = tf.placeholder(shape=(None,None),dtype=tf.int32,name='decoder_target')\n",
    "decoder_inputs = tf.placeholder(shape=(None,None),dtype=tf.int32,name='decoder_inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings\n",
    "embeddings = tf.Variable(tf.random_uniform(shape=(vocab_size,input_embedding_size),minval=-1,maxval=1,dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings,encoder_inputs)\n",
    "decoder_inputs_embedded = tf.nn.embedding_lookup(embeddings,decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Encoder\n",
    "encoder_cell = tf.contrib.rnn.LSTMCell(encoder_hidden_units)\n",
    "encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(cell=encoder_cell,inputs=encoder_inputs_embedded,dtype=tf.float32,time_major=True)\n",
    "del encoder_outputs  # not needed, we only use the final hidden state as input to decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 20) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_4:0' shape=(?, 20) dtype=float32>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_final_state # C is the state vector and h is the hidden sate vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoder\n",
    "decoder_cell = tf.contrib.rnn.LSTMCell(decoder_hidden_units)\n",
    "decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(cell=decoder_cell,inputs=decoder_inputs_embedded,\n",
    "                                                         initial_state=encoder_final_state,\n",
    "                                                         dtype=tf.float32,time_major=True,scope='plain_decoder'\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#projection layer\n",
    "decoder_logits = tf.contrib.layers.linear(inputs = decoder_outputs,num_outputs = vocab_size)\n",
    "decoder_prediction = tf.argmax(decoder_logits,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'fully_connected/BiasAdd:0' shape=(?, ?, 10) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "    labels = tf.one_hot(decoder_targets, depth=vocab_size,dtype=tf.float32),\n",
    "    logits = decoder_logits\n",
    "                       )\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING FORWARD PASS\n",
    "batch = [[6],\n",
    "        [3,4],\n",
    "        [9,8,7]]\n",
    "batch, batch_length = helpers.batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 3 9]\n",
      " [0 4 8]\n",
      " [0 0 7]] batch length =  [1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "print(batch, 'batch length = ',batch_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] dlen :  [1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "din, dlen = helpers.batch(np.ones(shape=(3,1),dtype=np.int32),max_sequence_length=4)\n",
    "print(din,'dlen : ',dlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder predictions \n",
      " [[3 5 3]\n",
      " [3 5 6]\n",
      " [0 0 6]\n",
      " [0 5 5]]\n"
     ]
    }
   ],
   "source": [
    "pred = sess.run(decoder_prediction,feed_dict={encoder_inputs:batch,decoder_inputs:din})\n",
    "print('decoder predictions \\n',str(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of the batch:\n",
      "[7, 3, 6, 4, 8, 5, 2, 8]\n",
      "[9, 6, 8, 5, 3, 2, 6]\n",
      "[5, 3, 7, 3, 8, 7, 2]\n",
      "[9, 5, 4, 6, 4, 7, 9]\n",
      "[7, 4, 2, 8]\n",
      "[9, 6, 9, 3, 7]\n",
      "[8, 5, 6, 3]\n",
      "[2, 9, 5, 3, 9]\n",
      "[3, 6, 5, 7, 4]\n",
      "[6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "#Training now \n",
    "batch_size = 100\n",
    "\n",
    "batches = helpers.random_sequences(length_from=3, length_to=8,\n",
    "                                   vocab_lower=2, vocab_upper=10,\n",
    "                                   batch_size=batch_size)    #0,and 1 are set to eos and pad\n",
    "\n",
    "print('head of the batch:')\n",
    "for seq in next(batches)[:10]:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    encoder_inputs_, _ = helpers.batch(batch)\n",
    "    decoder_targets_, _ = helpers.batch(\n",
    "        [(sequence) + [EOS] for sequence in batch]\n",
    "    )\n",
    "    decoder_inputs_, _ = helpers.batch(\n",
    "        [[EOS] + (sequence) for sequence in batch]\n",
    "    )\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        decoder_inputs: decoder_inputs_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }\n",
    "#Given encoder_inputs [5, 6, 7], decoder_targets would be [5, 6, 7, 1],\n",
    "# where 1 is for EOS, and decoder_inputs would be [1, 5, 6, 7] - decoder_inputs are lagged by 1 step, passing previous token as input at current step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_track = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.2818610668182373\n",
      "  sample 1:\n",
      "    input     > [8 3 6 3 5 4 0 0]\n",
      "    predicted > [5 5 3 3 3 3 3 3 5]\n",
      "  sample 2:\n",
      "    input     > [9 3 3 7 8 7 7 0]\n",
      "    predicted > [3 3 3 3 3 3 1 1 1]\n",
      "  sample 3:\n",
      "    input     > [6 4 2 6 7 6 0 0]\n",
      "    predicted > [3 3 3 3 6 3 6 6 6]\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.34204772114753723\n",
      "  sample 1:\n",
      "    input     > [9 9 9 7 5 3 6 2]\n",
      "    predicted > [9 9 9 7 5 3 6 6 1]\n",
      "  sample 2:\n",
      "    input     > [2 5 6 2 4 4 0 0]\n",
      "    predicted > [2 5 6 4 4 4 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [3 4 3 4 8 2 8 4]\n",
      "    predicted > [3 4 3 4 8 4 4 4 1]\n",
      "\n",
      "batch 2000\n",
      "  minibatch loss: 0.1506425142288208\n",
      "  sample 1:\n",
      "    input     > [9 7 3 7 5 7 0 0]\n",
      "    predicted > [9 7 7 7 5 7 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [9 7 8 3 5 3 0 0]\n",
      "    predicted > [9 7 8 3 5 3 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [7 4 2 5 2 6 5 0]\n",
      "    predicted > [7 4 2 5 2 6 5 1 0]\n",
      "\n",
      "batch 3000\n",
      "  minibatch loss: 0.13755765557289124\n",
      "  sample 1:\n",
      "    input     > [3 8 8 8 2 0 0 0]\n",
      "    predicted > [8 8 8 8 2 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [7 5 3 4 9 4 7 6]\n",
      "    predicted > [7 5 3 4 9 4 7 6 1]\n",
      "  sample 3:\n",
      "    input     > [2 8 6 5 5 6 0 0]\n",
      "    predicted > [2 8 6 5 5 6 1 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_batches = 3001\n",
    "batches_in_epoch = 1000\n",
    "\n",
    "try:\n",
    "    for batch in range(max_batches):\n",
    "        fd = next_feed()\n",
    "        _, l = sess.run([train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "\n",
    "        if batch == 0 or batch % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "            predict_ = sess.run(decoder_prediction, fd)\n",
    "            for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "                print('  sample {}:'.format(i + 1))\n",
    "                print('    input     > {}'.format(inp))\n",
    "                print('    predicted > {}'.format(pred))\n",
    "                if i >= 2:\n",
    "            print()\n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
